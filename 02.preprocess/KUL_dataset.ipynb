{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "136fc6dd",
   "metadata": {},
   "source": [
    "# Data process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eda9db12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:29:20.854338Z",
     "start_time": "2024-12-16T03:29:20.284431Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio \n",
    "import h5py, os,mne\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8191b687",
   "metadata": {},
   "source": [
    "## read EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9596009",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:29:23.219879Z",
     "start_time": "2024-12-16T03:29:20.856652Z"
    }
   },
   "outputs": [],
   "source": [
    "path = '/home/test/Desktop/python/EEG_data/AAD_dataset/AAD_KUL/RawEEGdata'\n",
    "file_path = os.path.join(path, 'S2.mat')\n",
    "data = sio.loadmat(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a4db7b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:29:23.224845Z",
     "start_time": "2024-12-16T03:29:23.221880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists and is ready to be opened.\n"
     ]
    }
   ],
   "source": [
    "# file_path\n",
    "if os.path.isfile(file_path):\n",
    "    print(\"File exists and is ready to be opened.\")\n",
    "else:\n",
    "    print(\"File not found. Please check the path:\", file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb71e1ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:29:23.557386Z",
     "start_time": "2024-12-16T03:29:23.227043Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check MAT file version and read it using SciPy library\n",
    "def extract_data_with_scipy(mat_file):\n",
    "    \"\"\"\n",
    "    Extract specific field data from a .mat file using SciPy for reading\n",
    "    \"\"\"\n",
    "    mat_data = sio.loadmat(mat_file)\n",
    "    \n",
    "    eeg_data_list = []  # List to store EEG data\n",
    "    stimuli_list = []   # List to store stimuli data\n",
    "    attended_ear_list = []  # List to store attended ear data\n",
    "\n",
    "#     # Print the content of mat_data to check its structure\n",
    "#     print(\"\\nKeys in mat_data:\", mat_data.keys())\n",
    "    trials = mat_data.get('trials', None)\n",
    "\n",
    "    if trials is not None:\n",
    "        for i in range(trials.shape[1]):\n",
    "            trial = trials[0, i]\n",
    "            \n",
    "            # Check for RawData\n",
    "            if 'RawData' in trial.dtype.names:\n",
    "                raw_data = trial['RawData'][0, 0]\n",
    "                eeg_data = raw_data['EegData']\n",
    "                eeg_data_list.append(eeg_data)\n",
    "            \n",
    "            # Check for stimuli\n",
    "            if 'stimuli' in trial.dtype.names:\n",
    "                stimuli = trial['stimuli']\n",
    "                stimuli_list.append(stimuli)\n",
    "            \n",
    "            # Check for attended_ear\n",
    "            if 'attended_ear' in trial.dtype.names:\n",
    "                attended_ear = trial['attended_ear']\n",
    "                attended_ear_list.append(attended_ear.item())\n",
    "                \n",
    "    return eeg_data_list, stimuli_list, attended_ear_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab1ca742",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:29:25.874259Z",
     "start_time": "2024-12-16T03:29:23.559350Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "eeg_data_list, stimuli_list, attended_ear_list = extract_data_with_scipy(file_path)\n",
    "\n",
    "# # Print or manipulate the extracted data\n",
    "# print(\"EEG Data: \", eeg_data_list)\n",
    "# print(\"Stimuli: \", stimuli_list)\n",
    "# print(\"Attended Ear: \", attended_ear_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b23a857",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:29:25.882257Z",
     "start_time": "2024-12-16T03:29:25.876204Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Extract filenames and simplify the structure\n",
    "def extract_filenames(stimuli):\n",
    "    filenames = []\n",
    "    for trial in stimuli:\n",
    "        trial_filenames = []\n",
    "        for file_array in trial[0, 0]:\n",
    "            trial_filenames.append([item[0] for item in file_array])\n",
    "        filenames.append(trial_filenames)\n",
    "    return filenames\n",
    "\n",
    "# Extract and simplify filenames\n",
    "simplified_filenames = extract_filenames(stimuli_list)\n",
    "\n",
    "# Comprehensive data extraction function\n",
    "def process_data(stimuli_list, attended_ear_list, eeg_data_list):\n",
    "\n",
    "    # Simplify stimuli filenames\n",
    "    stimuli_list_simplified = extract_filenames(stimuli_list)\n",
    "\n",
    "    # Extract 'R' or 'L' for attended ear\n",
    "    attended_ear_simplified = [ear[0] for ear in attended_ear_list]\n",
    "\n",
    "    # Simplify EEG data\n",
    "    eeg_data_list_simplified = [ear[0][0] for ear in eeg_data_list]\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    attended_ear_simplified = np.array(attended_ear_simplified)\n",
    "    stimuli_list_simplified = np.array(stimuli_list_simplified)\n",
    "\n",
    "    return stimuli_list_simplified, attended_ear_simplified, eeg_data_list_simplified\n",
    "\n",
    "# Call the function to process the data\n",
    "stimuli_filenames, attended_ear_simplified, eeg_data_list_simplified = process_data(stimuli_list, attended_ear_list, eeg_data_list)\n",
    "\n",
    "# Print results\n",
    "# print('Simplified Filenames:', simplified_filenames)\n",
    "\n",
    "# for files in stimuli_filenames:\n",
    "#     print(files)\n",
    "# print('Attended Ear Simplified:', attended_ear_simplified)\n",
    "# print('Number of Attended Ear:', len(attended_ear_simplified))\n",
    "# print('EEG Data List Simplified:', eeg_data_list_simplified)\n",
    "# print('Number of EEG Data:', len(eeg_data_list_simplified))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd0dcd76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:29:28.233921Z",
     "start_time": "2024-12-16T03:29:25.883713Z"
    }
   },
   "outputs": [],
   "source": [
    "eeg_data_list, stimuli_list, attended_ear_list = extract_data_with_scipy(file_path)\n",
    "stimuli_filenames, attended_ear_simplified, eeg_data_list_simplified = process_data(stimuli_list, attended_ear_list, eeg_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f654776",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:29:28.238691Z",
     "start_time": "2024-12-16T03:29:28.235852Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R'\n",
      " 'L' 'R']\n"
     ]
    }
   ],
   "source": [
    "print(attended_ear_simplified)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4512638",
   "metadata": {},
   "source": [
    "## Read audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6147cba3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:29:28.306242Z",
     "start_time": "2024-12-16T03:29:28.240124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "file_names = np.array(stimuli_filenames)\n",
    "print(file_names.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6badd7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:29:30.011779Z",
     "start_time": "2024-12-16T03:29:28.309743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44100\n",
      "(20, 2, 20811935)\n"
     ]
    }
   ],
   "source": [
    "import scipy.io.wavfile as wav\n",
    "\n",
    "# Assume you have a 1x20x2 string array\n",
    "file_names = np.array(stimuli_filenames)\n",
    "\n",
    "# Directory where the audio files are stored\n",
    "audio_dir = \"/home/test/Desktop/python/EEG_data/AAD_dataset/AAD_KUL/stimuli\"\n",
    "\n",
    "# Initialize a list to store the data of each audio file\n",
    "audio_data_list = []\n",
    "\n",
    "# Read each audio file\n",
    "for i in range(file_names.shape[0]):\n",
    "    for j in range(file_names.shape[1]):\n",
    "        file_path = os.path.join(audio_dir, file_names[i, j].item())  # Get full path to the audio file\n",
    "        sample_rate, audio_data = wav.read(file_path)  # Read the audio file\n",
    "        audio_data_list.append(audio_data)\n",
    "\n",
    "# Find the length of the longest audio signal\n",
    "max_length = max(len(audio) for audio in audio_data_list)\n",
    "\n",
    "# Initialize a 20x2xmax_length array, filling with 0 or NaN (depending on your needs)\n",
    "stacked_audio_data = np.zeros((file_names.shape[0], file_names.shape[1], max_length))\n",
    "\n",
    "# Fill the stacked array with each audio signal\n",
    "for idx, audio in enumerate(audio_data_list):\n",
    "    i, j = divmod(idx, file_names.shape[1])  # Calculate the corresponding indices for the 20x2 structure\n",
    "    stacked_audio_data[i, j, :len(audio)] = audio  # Assign the audio data\n",
    "\n",
    "# Print the sample rate and the shape of the stacked audio data\n",
    "print(sample_rate)\n",
    "print(stacked_audio_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63b3db57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:29:30.241482Z",
     "start_time": "2024-12-16T03:29:30.013494Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.signal as signal\n",
    "import librosa\n",
    "\n",
    "# Define the function to apply the Gammatone filter\n",
    "def apply_gammatone(audio_data, sample_rate, center_freq=440):\n",
    "    # Calculate the filter length\n",
    "    filter_length = int(16000*0.015)  # Choose an appropriate length\n",
    "    # Use scipy's gammatone function to create the filter\n",
    "    b, a = signal.gammatone(center_freq, ftype='fir', fs=sample_rate, numtaps=filter_length)\n",
    "    \n",
    "    # Apply the Gammatone filter\n",
    "    filtered_audio = signal.lfilter(b, a, audio_data)\n",
    "    \n",
    "    return filtered_audio\n",
    "\n",
    "def audio_stimuli(file_names):\n",
    "    # Directory for the audio files\n",
    "    audio_dir = \"/home/test/Desktop/python/EEG_data/AAD_dataset/AAD_KUL/stimuli\"\n",
    "\n",
    "    # Initialize a list to store the data for each audio file\n",
    "    audio_data_list = []\n",
    "\n",
    "    # Read each file\n",
    "    for i in range(file_names.shape[0]):\n",
    "        for j in range(file_names.shape[1]):\n",
    "            # Get the file name and replace 'hrtf' with 'dry'\n",
    "            updated_file_name = file_names[i, j].item().replace(\"hrtf\", \"dry\")\n",
    "#             print('updated_file_name', updated_file_name)\n",
    "            file_path = os.path.join(audio_dir, updated_file_name)\n",
    "            audio_data, sample_rate = librosa.load(file_path, sr=None)\n",
    "            audio_data = librosa.resample(audio_data, orig_sr=sample_rate, target_sr=16000)\n",
    "            \n",
    "            # Apply Gammatone filter and add it to the list\n",
    "            filtered_audio = apply_gammatone(audio_data, sample_rate, center_freq=440)\n",
    "            audio_data_list.append(filtered_audio)\n",
    "\n",
    "    # Find the length of the longest audio\n",
    "    max_length = max(len(audio) for audio in audio_data_list)\n",
    "\n",
    "    # Initialize a 20x2xmax_length array, fill with NaN or 0 based on your needs\n",
    "    stacked_audio_data = np.zeros((file_names.shape[0], file_names.shape[1], max_length))\n",
    "\n",
    "    # Fill the array with each audio signal\n",
    "    for idx, audio in enumerate(audio_data_list):\n",
    "        i, j = divmod(idx, file_names.shape[1])\n",
    "        stacked_audio_data[i, j, :len(audio)] = audio\n",
    "    \n",
    "    return stacked_audio_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598a5f4e",
   "metadata": {},
   "source": [
    "# stack_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38e568b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:29:30.913175Z",
     "start_time": "2024-12-16T03:29:30.243238Z"
    }
   },
   "outputs": [],
   "source": [
    "def slice_and_stack_data(eeg_data_list, attended_ear, audio_data, time_range, experiment_index):\n",
    "    # Sampling rate\n",
    "    eeg_sample_rate = 128\n",
    "    audio_sample_rate = 16000\n",
    "    \n",
    "    # Encode left and right ears as 0 and 1\n",
    "    ear_label_map = {'R': 1, 'L': 0}\n",
    "    ear_labels = np.array([ear_label_map[ear] for ear in attended_ear])\n",
    "\n",
    "    # Select the EEG data, ear labels, and audio data for the specified experiment\n",
    "    eeg_data = eeg_data_list[experiment_index]\n",
    "    ear_label = ear_labels[experiment_index]\n",
    "    audio = audio_data[experiment_index]\n",
    "    \n",
    "    # Determine the number of samples per slice for EEG and audio\n",
    "    eeg_sample_count = int(eeg_sample_rate * time_range)\n",
    "    audio_sample_count = int(audio_sample_rate * time_range)\n",
    "    \n",
    "    \n",
    "    eeg_length_sec = int(eeg_data.shape[0] // eeg_sample_count)\n",
    "    audio_length_sec = int(audio.shape[1] // audio_sample_count)\n",
    "    \n",
    "#     print('eeg_length_sec, audio_length_sec = ', eeg_length_sec, audio_length_sec)\n",
    "    \n",
    "    # Calculate the total number of slices\n",
    "    total_slices = min(eeg_length_sec, audio_length_sec)\n",
    "\n",
    "    # Initialize lists to store the sliced data\n",
    "    sliced_eeg_data = []\n",
    "    sliced_audio_data = []\n",
    "    sliced_ear_labels = []\n",
    "\n",
    "    # Slice and stack the data\n",
    "    for i in range(total_slices):\n",
    "        start_eeg_sample = i * eeg_sample_count\n",
    "        end_eeg_sample = start_eeg_sample + eeg_sample_count\n",
    "        start_audio_sample = i * audio_sample_count\n",
    "        end_audio_sample = start_audio_sample + audio_sample_count\n",
    "\n",
    "        eeg_slice = eeg_data[start_eeg_sample:end_eeg_sample]\n",
    "        audio_slice = audio[:, start_audio_sample:end_audio_sample]\n",
    "\n",
    "        # Transpose EEG data to (64, 128)\n",
    "        eeg_slice = np.transpose(eeg_slice, (1, 0))\n",
    "\n",
    "        sliced_eeg_data.append(eeg_slice)\n",
    "        sliced_audio_data.append(audio_slice)\n",
    "        sliced_ear_labels.append([ear_label])\n",
    "    \n",
    "    # Convert the lists into arrays\n",
    "    stacked_eeg_data = np.array(sliced_eeg_data)\n",
    "    stacked_audio_data = np.array(sliced_audio_data)\n",
    "    stacked_ear_labels = np.array(sliced_ear_labels)\n",
    "    \n",
    "    return stacked_eeg_data, stacked_audio_data, stacked_ear_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03d77d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7a9a3cd",
   "metadata": {},
   "source": [
    "# integrate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4ae5118",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:29:31.084219Z",
     "start_time": "2024-12-16T03:29:30.915286Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_sub_experiment_data(root, sub_file, time_range, experiment_index): \n",
    "    \"\"\"\n",
    "        root = Root directory\n",
    "        sub_file_path = Select subject\n",
    "        time_range = Time length [0.5, 1, 1.5, 2]\n",
    "        experiment_index = Experiment selection [0:1:19]\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(root, sub_file)\n",
    "    print(file_path)\n",
    "    print('Processing subject {} experiment {}'.format(sub_file, experiment_index))\n",
    "    eeg_data_list, stimuli_list, attended_ear_list = extract_data_with_scipy(file_path)  # Read formatted data\n",
    "    stimuli_filenames, attended_ear, eeg_data_list = process_data(stimuli_list, attended_ear_list, eeg_data_list)  # Remove formatting\n",
    "    audio_data = audio_stimuli(stimuli_filenames)\n",
    "    stacked_eeg_data, stacked_audio_data, stacked_ear_labels = slice_and_stack_data(eeg_data_list, attended_ear, audio_data, time_range, experiment_index)\n",
    "    \n",
    "    # Print the shapes of the output\n",
    "    print(\"EEG_data shape:\", stacked_eeg_data.shape)  # Expected output (100, 64, 128)\n",
    "    print(\"Audio_data shape:\", stacked_audio_data.shape)  # Expected output (100, 2, 16000)\n",
    "    print(\"Ear_labels shape:\", stacked_ear_labels.shape)  # Expected output (100, 1)\n",
    "\n",
    "    return stacked_eeg_data, stacked_audio_data, stacked_ear_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5f3a5d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:29:31.162431Z",
     "start_time": "2024-12-16T03:29:31.085956Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_sub_all_data(root, sub_file, time_range):\n",
    "    \"\"\"\n",
    "        root = Root directory\n",
    "        sub_file_path = Select subject\n",
    "        time_range = Time length [0.5, 1, 1.5, 2]\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(root, sub_file)\n",
    "    print(file_path)\n",
    "    print('Processing subject {}'.format(sub_file))\n",
    "    eeg_data_list, stimuli_list, attended_ear_list = extract_data_with_scipy(file_path)  # Read formatted data\n",
    "    stimuli_filenames, attended_ear, eeg_data_list = process_data(stimuli_list, attended_ear_list, eeg_data_list)  # Remove formatting\n",
    "    audio_data = audio_stimuli(stimuli_filenames)\n",
    "    \n",
    "    all_stacked_eeg_data = []\n",
    "    all_stacked_audio_data = []\n",
    "    all_stacked_ear_labels = []\n",
    "    \n",
    "    for experiment_index in range(20):\n",
    "        stacked_eeg_data, stacked_audio_data, stacked_ear_labels = slice_and_stack_data(eeg_data_list, attended_ear, audio_data, time_range, experiment_index)\n",
    "        all_stacked_eeg_data.append(stacked_eeg_data)\n",
    "        all_stacked_audio_data.append(stacked_audio_data)\n",
    "        all_stacked_ear_labels.append(stacked_ear_labels)\n",
    "    \n",
    "    # Vertically stack all the experiment data\n",
    "    all_stacked_eeg_data = np.vstack(all_stacked_eeg_data)\n",
    "    all_stacked_audio_data = np.vstack(all_stacked_audio_data)\n",
    "    all_stacked_ear_labels = np.vstack(all_stacked_ear_labels)\n",
    "    \n",
    "    # Print the shapes of the output\n",
    "    print(\"EEG_data shape:\", all_stacked_eeg_data.shape)  # Expected output (2000, 64, 128)\n",
    "    print(\"Audio_data shape:\", all_stacked_audio_data.shape)  # Expected output (2000, 2, 16000)\n",
    "    print(\"Ear_labels shape:\", all_stacked_ear_labels.shape)  # Expected output (2000, 1)\n",
    "\n",
    "    return all_stacked_eeg_data, all_stacked_audio_data, all_stacked_ear_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "deb26c14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:29:54.693691Z",
     "start_time": "2024-12-16T03:29:31.164525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/test/Desktop/python/EEG_data/AAD_dataset/AAD_KUL/RawEEGdata/S3.mat\n",
      "Processing subject S3.mat\n",
      "EEG_data shape: (4624, 64, 128)\n",
      "Audio_data shape: (4624, 2, 16000)\n",
      "Ear_labels shape: (4624, 1)\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "root = '/home/test/Desktop/python/EEG_data/AAD_dataset/AAD_KUL/RawEEGdata'\n",
    "sub_file = 'S3.mat'\n",
    "time_range = 1  # second\n",
    "all_stacked_eeg_data, all_stacked_audio_data, all_stacked_ear_labels = get_sub_all_data(root, sub_file, time_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3da3b3e",
   "metadata": {},
   "source": [
    "## process dataset for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0deb61e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:31:22.959119Z",
     "start_time": "2024-12-16T03:31:22.954737Z"
    }
   },
   "outputs": [],
   "source": [
    "def stack_and_save_data(root, sub_files, time_range, save_path):\n",
    "    all_eeg_data = []\n",
    "    all_audio_data = []\n",
    "    all_ear_labels = []\n",
    "\n",
    "    for sub_file in sub_files:\n",
    "        eeg_data, audio_data, ear_labels = get_sub_all_data(root, sub_file, time_range)\n",
    "        all_eeg_data.append(eeg_data)\n",
    "        all_audio_data.append(audio_data)\n",
    "        all_ear_labels.append(ear_labels)\n",
    "\n",
    "    all_eeg_data = np.array(all_eeg_data)\n",
    "    all_audio_data = np.array(all_audio_data)\n",
    "    all_ear_labels = np.array(all_ear_labels)\n",
    "\n",
    "    # Save as a .npz file\n",
    "    np.savez('all_data.npz', eeg=all_eeg_data, audio=all_audio_data, ear=all_ear_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b073e02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:31:30.793439Z",
     "start_time": "2024-12-16T03:31:30.790362Z"
    }
   },
   "outputs": [],
   "source": [
    "root = '/home/test/Desktop/python/EEG_data/AAD_dataset/AAD_KUL/RawEEGdata'\n",
    "sub_files = [f'S{i}.mat' for i in range(1, 17)]\n",
    "time_range = 1  # Unit: seconds\n",
    "save_path = '/home/test/Desktop/python/EEG_data/AAD_dataset/AAD_KUL/Dataset_single_drywav'  # Replace with actual save path\n",
    "\n",
    "stack_and_save_data(root, sub_files, time_range, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa523390",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "318.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
